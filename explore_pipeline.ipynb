{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to explore the whole process of building a Langchain project to detect when a conversation is going to an inappropiate place, specially aiming to protect young children and adolescents that can become easy targets for pedophiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from preprocess.clear_data import xml2csv\n",
    "import pandas as pd\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Load the \"training\" data, which will be the Document Store\n",
    "DATA_PATH = os.getenv(\"DATA\")\n",
    "CORPUS_DATA_PATH = os.getenv(\"CORPUS_DATA\") #xml file\n",
    "PREDATORS_DATA_PATH = os.getenv(\"PREDATORS_DATA\") #txt file\n",
    "\n",
    "# Load the \"test\" data to test the model\n",
    "CORPUS_TEST_DATA_PATH = os.getenv(\"CORPUS_TEST_DATA\") #xml file\n",
    "PREDATORS_TEST_DATA_PATH = os.getenv(\"PREDATORS_TEST_DATA\") #txt file\n",
    "\n",
    "# Load the necessary keys for the APIs\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = os.getenv(\"GOOGLE_CSE_ID\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"QDRANT_API_KEY\"] = os.getenv(\"QDRANT_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project data can be download from https://pan.webis.de/clef12/pan12-web/sexual-predator-identification.html please be sure to read all the necessary documentation to deeply understand it. The files were renamed and some were erased, but feel free to explore them and integrate them to the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, I used the preprocessing files from https://github.com/aaarguel/pan_identification to convert the xml \n",
    "# files to a more amicable CSV file. The csv contain the following columns:\n",
    "# CONVERSATION_ID, AUTHORS_IDS, IS_ABUSIVE, CONVERSATION_TEXT\n",
    "# The CONVERSATION_TEXT has all the consecutive messages separated by |\n",
    "\n",
    "# Load the training data, in this case only load the abusive cases to store them in Qdrant.\n",
    "xml2csv(nameXML=CORPUS_DATA_PATH,nameCSV=\"csv_files/abusive_text.csv\",predatorsTXT=PREDATORS_DATA_PATH, only_abusive=True)\n",
    "# Load the test data, in this case load all the cases to test the model.\n",
    "xml2csv(nameXML=CORPUS_TEST_DATA_PATH,nameCSV=\"csv_files/abusive_text_test.csv\",predatorsTXT=PREDATORS_TEST_DATA_PATH, only_abusive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data using the doc loader from langchain, make sure to specify the content, \n",
    "# source and metadata columns\n",
    "loader = CSVLoader(\n",
    "    file_path=\"csv_files/abusive_text.csv\",\n",
    "    csv_args={\n",
    "        \"delimiter\": \";\",\n",
    "        \"fieldnames\": [\"CONVERSATION_ID\", \"AUTHORS_IDS\", \"IS_ABUSIVE\", \"CONVERSATION_TEXT\"],\n",
    "    },\n",
    "    content_columns=[\"CONVERSATION_TEXT\"],\n",
    "    source_column=\"CONVERSATION_ID\",\n",
    "    metadata_columns=[\"AUTHORS_IDS\"],\n",
    ")\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the RecursiveCharacterTextSplitter class with specific parameters.\n",
    "# It splits text into chunks of 1000 characters each with a 150-character overlap.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "\n",
    "# 'splits' holds the text you want to split, split the text into documents using the text splitter.\n",
    "splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Qdrant to load the data into the vector store, using an embedding function to convert the text into vectors.\n",
    "qdrant_url = os.getenv(\"QDRANT_URL\")\n",
    "qdrant_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "\n",
    "embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "qdrant = QdrantVectorStore.from_documents(\n",
    "    splits,\n",
    "    embedding_function,\n",
    "    url=qdrant_url,\n",
    "    prefer_grpc=True,\n",
    "    api_key=qdrant_key,\n",
    "    collection_name=\"groom_chats\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The documents should load only one time, of course if you need to load more data you can do it.\n",
    "# Now, we will retrieve the data from the Qdrant store to test the model.\n",
    "qdrant = QdrantVectorStore.from_existing_collection(\n",
    "    embedding=embedding_function,\n",
    "    collection_name=\"groom_chats\",\n",
    "    url=qdrant_url,\n",
    "    api_key=qdrant_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = qdrant.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_docs(chunks):\n",
    "    return \"\\n\\n\".join(chunk.page_content for chunk in chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert on detecting grooming on chat conversations. \n",
    "This are some grooming chat examples, keep in mind that conversation \n",
    "messages are separated by a | character. \n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "Taking into account the previous examples, do you identify any grooming behavior \n",
    "in the next chat? Answer if the conversation is grooming or not, and\n",
    "give the literal text that makes you think so.\n",
    "\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo de OpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.8)\n",
    "\n",
    "# Definimos el chain con el pipeline integrado\n",
    "chain = (\n",
    "        {\"context\": retriever | join_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should test the model with a test conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"csv_files/abusive_text_test.csv\", delimiter=\";\", names=[\"CONVERSATION_ID\", \"AUTHORS_IDS\", \"IS_ABUSIVE\", \"CONVERSATION_TEXT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, this conversation exhibits grooming behavior. The phrases \"hello there\", \"how are ya?\", \"hey\", and \"where are you from, Stranger\" all show an attempt to establish a connection, gather personal information, and potentially manipulate the individual.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(df.iloc[4]['CONVERSATION_TEXT'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
